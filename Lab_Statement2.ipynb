{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, poisson\n",
    "\n",
    "class CovidMDP:\n",
    "    def __init__(self, num_beds=650, population=[0.38, 0.33, 0.23, 0.06], num_weeks=4,\n",
    "                 bed_conversion_cost=5000, normal_bed_denial_cost=1000, covid_bed_denial_cost=5000):\n",
    "        self.num_beds = num_beds\n",
    "        self.population = np.array(population)\n",
    "        self.num_weeks = num_weeks\n",
    "        self.bed_conversion_cost = bed_conversion_cost\n",
    "        self.normal_bed_denial_cost = normal_bed_denial_cost\n",
    "        self.covid_bed_denial_cost = covid_bed_denial_cost\n",
    "        self.start_state = (self.num_beds, np.zeros(len(self.population)), np.zeros(len(self.population)),\n",
    "                            np.zeros(len(self.population)), np.zeros(len(self.population)))\n",
    "        self.end_state = None\n",
    "        self.num_states = 0\n",
    "        self.num_actions = 0\n",
    "        self.states = {}\n",
    "        self.actions = {}\n",
    "        self.rewards = {}\n",
    "        self.transition_probs = {}\n",
    "\n",
    "        # Define the possible states and actions\n",
    "        for i in range(self.num_beds + 1):\n",
    "            for j in range(self.num_beds + 1 - i):\n",
    "                for k in range(self.num_weeks):\n",
    "                    for l in range(len(self.population)):\n",
    "                        for m in range(len(self.population)):\n",
    "                            state = (i, j, k, l, m)\n",
    "                            self.states[state] = self.num_states\n",
    "                            self.num_states += 1\n",
    "        for i in range(self.num_beds + 1):\n",
    "            for j in range(self.num_weeks):\n",
    "                action = (i, j)\n",
    "                self.actions[action] = self.num_actions\n",
    "                self.num_actions += 1\n",
    "\n",
    "        # Define the reward function\n",
    "        for state in self.states:\n",
    "            for action in self.actions:\n",
    "                r = 0\n",
    "                beds_normal, beds_covid, week, pop_before, pop_after = state\n",
    "                beds_normal_new = beds_normal - action[0]\n",
    "                beds_covid_new = beds_covid + action[0] + action[1]\n",
    "                pop_migrated = np.round(norm.rvs(0, 1, size=len(self.population)) * 1000)\n",
    "                pop_before_new = pop_before + pop_migrated\n",
    "                pop_after_new = pop_after + pop_migrated\n",
    "                for p in range(len(self.population)):\n",
    "                    requests_normal = poisson.rvs(pop_after_new[p] * beds_normal_new / self.num_beds)\n",
    "                    discharges_normal = poisson.rvs(beds_normal_new)\n",
    "                    denied_normal = max(requests_normal - discharges_normal, 0)\n",
    "                    requests_covid = poisson.rvs(pop_after_new[p] * beds_covid_new / self.num_beds)\n",
    "                    discharges_covid = poisson.rvs(beds_covid_new)\n",
    "                    denied_covid = max(requests_covid - discharges_covid, 0)\n",
    "                    r += self.normal_bed_denial_cost * denied_normal + \\\n",
    "                         self.covid_bed_denial_cost * denied_covid + \\\n",
    "                         self.bed_conversion_cost * (action[0] + action[1])\n",
    "                self.rewards[(self.states[state], self.actions[action])] = -r\n",
    "\n",
    "        # Define the transition probabilities\n",
    "        for state in self.states:\n",
    "            for action in self.actions:\n",
    "                prob_dict = {}\n",
    "                beds_normal, beds_covid, week, pop_before, pop_after = state\n",
    "                beds_normal_new = beds_normal - action[0]\n",
    "                beds_covid_new = beds_covid + action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def policy_evaluation_gbike(policy, Lamda, lamda, r, t, gam):\n",
    "# Implement policy evaluation for gbike problem\n",
    "# Returns state value V for the given policy\n",
    "    n_states = (21)**2\n",
    "    n_actions = 11\n",
    "    T = np.zeros((n_states, n_states, n_actions))\n",
    "    R = np.zeros((n_states, n_actions))\n",
    "    P = np.zeros((n_states, n_actions, n_states))\n",
    "    V = np.zeros((21, 21))\n",
    "\n",
    "    # Calculate transition probabilities and rewards for all states and actions\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            state = i*21 + j\n",
    "            for action in range(n_actions):\n",
    "                na1 = min(i+action-5, 20) # number of available bikes at location 1 after action\n",
    "                na2 = min(j-action+5, 20) # number of available bikes at location 2 after action\n",
    "                for r1 in range(21):\n",
    "                    for r2 in range(21):\n",
    "                        p = poisson_prob(r1, Lamda[0]) * poisson_prob(r2, Lamda[1]) # probability of rental requests\n",
    "                        rent1 = min(na1, r1) # number of bikes rented at location 1\n",
    "                        rent2 = min(na2, r2) # number of bikes rented at location 2\n",
    "                        reward = (rent1 + rent2) * r # rental reward\n",
    "                        nr1 = na1 - rent1 + min(lamda[0], 20-na1+rent1) # number of available bikes at location 1 after returns\n",
    "                        nr2 = na2 - rent2 + min(lamda[1], 20-na2+rent2) # number of available bikes at location 2 after returns\n",
    "                        ns = nr1*21 + nr2 # next state\n",
    "                        R[state, action] += p * reward # reward for current state and action\n",
    "                        T[state, ns, action] += p # transition probability for current state, action, and next state\n",
    "\n",
    "    # Perform policy evaluation\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for i in range(21):\n",
    "            for j in range(21):\n",
    "                state = i*21 + j\n",
    "                v = 0\n",
    "                for action in range(n_actions):\n",
    "                    v_a = 0\n",
    "                    for ns in range(n_states):\n",
    "                        v_a += T[state, ns, action] * (R[state, action] + gam * V[ns//21, ns%21])\n",
    "                    v += policy[i, j, action] * v_a\n",
    "                delta = max(delta, abs(v - V[i, j]))\n",
    "                V[i, j] = v\n",
    "        if delta < 1e-4:\n",
    "            break\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement_gbike(V, policy, Lamda, lamda, r, t, gam):\n",
    "# Implement policy improvement for gbike problem\n",
    "# Returns new policy and a boolean indicating if the policy has stabilized\n",
    "\n",
    "    n_states = (21)**2\n",
    "    n_actions = 11\n",
    "    new_policy = np.zeros((21, 21, n_actions))\n",
    "    P = np.zeros((n_states, n_actions, n_states))\n",
    "    R = np.zeros((n_states, n_actions))\n",
    "    policystable = True\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            state = i*21 + j\n",
    "            for action in range(n_actions):\n",
    "                na1 = min(i+action-5, 20) # number of available bikes at location 1 after action\n",
    "                na2 = min(j-action+5, 20) # number of available bikes at location 2 after action\n",
    "                for r1 in range(21):\n",
    "                    for r2 in range(21):\n",
    "                        p = poisson_prob(r1, Lamda[0]) * poisson_prob(r2, Lamda[1]) # probability of rental requests\n",
    "                        rent1 = min(na1, r1) # number of bikes rented at location 1\n",
    "                        rent2 = min(na2, r2) # number of bikes rented at location 2\n",
    "                        reward = (rent1 + rent2) * r # rental reward\n",
    "                        nr1 = na1 - rent1 + min(lamda[0], 20-na1+rent1) # number of available bikes at location 1 after returns\n",
    "                        nr2 = na2 - rent2 + min(lamda[1], 20-na2+rent2) # number of available bikes at location 2 after returns\n",
    "                        ns = nr1*21 + nr2 # next state\n",
    "                        R[state, action] += p * reward # reward for current state and action\n",
    "                        P[state, action, ns] += p # transition probability for current state, action, and next state\n",
    "\n",
    "    # Perform policy improvement\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            state = i*21 + j\n",
    "            q = np.zeros(n_actions)\n",
    "            for action in range(n_actions):\n",
    "                for ns in range(n_states):\n",
    "                    q[action] += P[state, action, ns] * (R[state, action] + gam * V[ns//21, ns%21])\n",
    "            best_action = np.argmax(q)\n",
    "            new_policy[i, j, best_action] = 1\n",
    "            if not np.array_equal(new_policy[i, j, :], policy[i, j, :]):\n",
    "                policystable = False\n",
    "    return new_policy, policystable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_prob(n, lam):\n",
    "# Calculate the probability of n occurrences given the rate parameter lam using Poisson distribution\n",
    "    return lam**n * np.exp(-lam) / np.math.factorial(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
